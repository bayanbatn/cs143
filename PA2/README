README file for Programming Assignment 2 (Java edition)
=======================================================

Your directory should now contain the following files:

 Makefile		  -> [course dir]/src/PA2J/Makefile
 README
 cool.cup
 bad.cl
 good.cl
 cool-tree.java		  -> [course dir]/src/PA2J/cool-tree.java
 cool-tree.aps		  -> [course dir]/src/PA2J/cool-tree.aps
 AbstractSymbol.java	  -> [course dir]/src/PA2J/AbstractSymbol.java
 AbstractTable.java	  -> [course dir]/src/PA2J/AbstractTable.java
 BoolConst.java		  -> [course dir]/src/PA2J/BoolConst.java
 CgenClassTable.java	  -> [course dir]/src/PA2J/CgenClassTable.java
 CgenNode.java		  -> [course dir]/src/PA2J/CgenNode.java
 CgenSupport.java	  -> [course dir]/src/PA2J/CgenSupport.java
 ClassTable.java	  -> [course dir]/src/PA2J/ClassTable.java
 CoolParser.java	  -> [course dir]/src/PA2J/CoolParser.java
 CoolTokenLexer.java	  -> [course dir]/src/PA2J/CoolTokenLexer.java
 Flags.java		  -> [course dir]/src/PA2J/Flags.java
 IdSymbol.java		  -> [course dir]/src/PA2J/IdSymbol.java
 IdTable.java		  -> [course dir]/src/PA2J/IdTable.java
 IntSymbol.java		  -> [course dir]/src/PA2J/IntSymbol.java
 IntTable.java		  -> [course dir]/src/PA2J/IntTable.java
 ListNode.java		  -> [course dir]/src/PA2J/ListNode.java
 Parser.java		  -> [course dir]/src/PA2J/Parser.java
 StringSymbol.java	  -> [course dir]/src/PA2J/StringSymbol.java
 StringTable.java	  -> [course dir]/src/PA2J/StringTable.java
 SymbolTable.java	  -> [course dir]/src/PA2J/SymbolTable.java
 TokenConstants.java	  -> [course dir]/src/PA2J/TokenConstants.java
 TreeConstants.java	  -> [course dir]/src/PA2J/TreeConstants.java
 TreeNode.java		  -> [course dir]/src/PA2J/TreeNode.java
 Utilities.java		  -> [course dir]/src/PA2J/Utilities.java
 *.java			  other generated files

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.
    
	The README contains this info. Part of the assignment is to
	fill in the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and why
	your test cases are adequate. It is part of the assignment to
	clearly and concisely explain things in text as well as to comment
	your code. Just edit this file.

	cool.cup is the skeleton for the parser specification that you
	are to write. It already contains productions for the program
	and the classes. Use them as an example to write the remaining
	productions.  You should also read the CUP documentation.
	This skeleton will compile and run as is, but it doesn't
	do much.

	good.cl, bad.cl test a few features of the grammar. You should
	add tests to ensure that good.cl exercises every legal
	construction of the grammar and that bad.cl exercises as many
	different parsing errors as you can squeeze into one file.

	cool-tree.aps contains the definitions for the tree language
	which you use to construct the abstract syntax tree (AST).  From
	this file, cool-tree.java is automatically generated by a
	utility that compiles the specification into Java classes for
	constructing tree nodes.  This file is provided for your
	reference.  DO NOT MODIFY.

        TreeNode.java and ListNode.java contain definitions used by the
        tree package. DO NOT MODIFY.  

        Parser.java contains a driver to test the parser. DO NOT MODIFY.

	Flags.java implements routines for parsing command line
	flags. DO NOT MODIFY.

        The rest of the files are created as byproducts of `CUP', or
        are internal parser support files.  DO NOT MODIFY.
        `CoolParser.java' is the generated Java file containing the
        parser.  DO NOT MODIFY this file directly; instead, edit
        cool.cup and this file will be regenerated automatically.

	Files not discussed are covered in the README for PA2J.

Instructions
------------

	To compile your parser program type:

	% make parser

	This compiles all the classes and produces an shell script named
	"parser" which invokes Parser.main() as the standalone phase of
	the Cool compiler.  It requires lexer, semant, and cgen to do
	anything useful.

	To run your parser on the files good.cl and bad.cl type:

	% make dotest

	To run the (provided) lexer and your parser on a file called test.cl type:

	% ./lexer test.cl | ./parser

	If you think your parser is correct and behaves like
	the one we wrote, you may want to run a COOL compiler using
	your parser:

	% ./mycoolc foo.cl

	To overwrite the default lexical analyzer with yours, replace 
	lexer (which is a symbolic link to the "official" lexer) with
        your lexer from PA2.

	To turnin your work type:

	% make submit

	Running "submit" will collect the files cool.cup, good.cl, bad.cl,
	good.output, bad.output, and README. Don't forget to edit the
	README file to include your write-up, and to write your own test
	cases in good.cl and bad.cl.

 	You may turn in the assignment as many times as you like.
	However, only the last version will be retained for
	grading.

	If you change architectures you must issue

	% make clean

	when you switch from one type of machine to the other.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA2J
-----------------

Nonterminal Symbols
====================
Most of the nonterminal phylum match the COOL SYNTAX formulae given in the 
cool manual. Not terribly interesting. A few non-terminals that I personally 
added are:

non_empty_feature_list : a non empty list of features
non_empty_formal_list: a non-empty list of formals
non_empty_expr_list: a list of expressions separated out by 
                     comma, cannot be empty
sc_separated_expr_list: a list of expressions separated by a 
                        semicolon, cannot be empty

The non-empty versions of the phyla were added to remove possible left recursion
issues, and make the syntax formulation more clear and concise.


Precedence rules
====================
Followed the precedence and associativity rules outlined in the COOL manual
provided by the class. This meant letting DOT and AT be the highest precdence
symbols for example, and defining ASSIGN to be right associative, EQ, LT, LE 
to be non-associative, and everything else to be left associative.


Error recovery
====================
We perform error recovery from lists of classes, lists of features, lists of
arguments in let expressions, and lists of expressions in block expressions.
When appropriate, we defer error recovery to down the line. For example,
we do not detect errors for "feature_list" inside the "class" definition - this 
would be much better handled inside the "feature" nonterminal. 


Testing
====================
I filled out the cool files, "good.cl" and "bad.cl", with code for testing edge 
cases in both the good and the bad cases. "good.cl" contains code for testing all
cool syntax expressions. Every terminal symbol and its use is tested at least one
in this file, and the syntax is correctly used. I wrote a script to test the output
of my parser against that of the reference solution (minus the differences in line 
numbers), and made sure there weren't any inconsistencies in the AST output from
either parsers.

I also included code in "bad.cl" to test out our implementation of error recovery.
Since error recovery was implemented for lists of classes, lists of features,
lists of arguments in let expression, and list of expressions in the block
expression, these syntax error are stress tested. I define multiple classes
with various syntactical errors to test error handling in class definition.
However, within the class definition, error contained in the feature_list is
not handled, as that should be more appropriately handled down the line. 

We also similary defined classes and features to test out the rest of the 
error recovery. In several cases, we noticed our parser recovered from errors
better than the reference solution. Some examples of such cases include
class definition that is missing "CLASS" keyword, empty block expressions,
and use of TYPEID instead of OBJECTID in arguments of let expressions. While
our parser can immidiately detect such cases, the reference parser was unable to
find them immidiately, which resulted in it discovering error artifacts down 
the line.
