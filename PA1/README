README file for Programming Assignment 1 (Java edition)
=======================================================

Your directory should now contain the following files:

 Makefile
 README
 cool.lex
 test.cl
 AbstractSymbol.java  -> [course dir]/src/PA1J/AbstractSymbol.java
 BoolConst.java       -> [course dir]/src/PA1J/BoolConst.java
 Flags.java           -> [course dir]/src/PA1J/Flags.java
 IdSymbol.java        -> [course dir]/src/PA1J/IdSymbol.java
 IdTable.java         -> [course dir]/src/PA1J/IdTable.java
 IntSymbol.java       -> [course dir]/src/PA1J/IntSymbol.java
 IntTable.java        -> [course dir]/src/PA1J/IntTable.java
 Lexer.java           -> [course dir]/src/PA1J/Lexer.java
 AbstractTable.java   -> [course dir]/src/PA1J/AbstractTable.java
 StringSymbol.java    -> [course dir]/src/PA1J/StringSymbol.java
 StringTable.java     -> [course dir]/src/PA1J/StringTable.java
 Utilities.java       -> [course dir]/src/PA1J/Utilities.java
 TokenConstants.java  -> [course dir]/src/PA1J/TokenConstants.java
 *.java		      other generated files

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code. Just edit this file.

	cool.lex is a skeleton file for the specification of the
	lexical analyzer. You should complete it with your regular
	expressions, patterns and actions. 

	test.cl is a COOL program that you can test the lexical
	analyzer on. It contains some errors, so it won't compile with
	coolc. However, test.cl does not exercise all lexical
	constructs of COOL and part of your assignment is to rewrite
	test.cl with a complete set of tests for your lexical analyzer.

	TokenConstants.java contains constant definitions that are used by
	almost all parts of the compiler. DO NOT MODIFY.

	*Table.java and *Symbol.java contain string table data
	structures.  DO NOT MODIFY.

	Utilities.java contains various support functions used by the
	main lexer driver (Lexer.java).  DO NOT MODIFY.

	Lexer.java contains the main method which will call your lexer
	and print out the tokens that it returns.  DO NOT MODIFY.

        CoolLexer.java is the scanner generated by jlex from cool.lex.
        DO NOT MODIFY IT, as your changes will be overritten the next
        time you run jlex.

	mycoolc is a shell script that glues together the phases of the
	compiler using Unix pipes instead of statically linking code.  
	While inefficient, this architecture makes it easy to mix and match
	the components you write with those of the course compiler.
	DO NOT MODIFY.	

Instructions
------------

	To compile your lextest program type:

	% make lexer

	Run your lexer by putting your test input in a file 'foo.cl' and
	run the lextest program:

	% lexer foo.cl

	To run your lexer on the file test.cl type:

	% make dotest

	If you think your lexical analyzer is correct and behaves like
	the one we wrote, you can actually try 'mycoolc' and see whether
	it runs and produces correct code for any examples.
	If your lexical analyzer behaves in an
	unexpected manner, you may get errors anywhere, i.e. during
	parsing, during semantic analysis, during code generation or
	only when you run the produced code on spim. So beware.

	To turnin your work type:

	% make submit

	Running "submit" will collect the files cool.lex, test.cl,
	README, and test.output. Don't forget to edit the README file to
	include your write-up, and to write your own test cases in
	test.cl.

 	You may turn in the assignment as many times as you like.
	However, only the last version will be retained for
	grading.

	If you change architectures you must issue

	% make clean

	when you switch from one type of machine to the other.


	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA1J
-----------------
TODO: nested comments
TODO: EOF in string end and max char
I'm breaking this project into several components.

** States:
In addition to the default YYINITIAL state, I define 3 new states:
STRING_STATE, LINE_COMMENT, and BLOCK_COMMENT. These states are activated
when we encounter special characters ("\"" for string, and "\(\*" and "--"
for comments). 

** Regex matching:
Most regex matches are handled by returning an AbstractSymbol object
We have to make sure that constructs such as methods, blocks, loops, string
constants, and parenthesis are appropriately matched at both ends. To do so,
we define the approriate states for each of these constructs. We then use a
LIFO data structure to ensure that matched-constructs are closed off in the reverse
order as their beginning.

Error-free code should have an empty stack by the time we reach its EOF.
of the appropriate type, without initializing value. The interesting scenarios
are when we handles comments and string constants.

We handle string constant parsing inside the STRING_STATE, which is triggered
with a quotes character. We perform regex matching that ensures that the
end of the string is reached in the input. This means the matching token must
have a trailing newline or quotes character at the end, which ends the string.
Once we find a match, we back into YYINITIAL state, regardless of the result
of the parsing. By iterating through the characters of the matching token, we 
detect and handle any formatting error on the string constants while ensuring
that escaped characters are properly processed. We also detect any escaped
new line chars (both legal and illegal) to update line numbers.

We handle comments inside the LINE_COMMENT and BLOCK_COMMENT states. Tokens
read in the comment states are disregarded (except for new line chars, which
are used to update line number). 

TODO: nested comments

** Error Handling:
EOF are handles inside the eofval{} block. If we are in any state other than
YYINITIAL, reading EOF will result in an error symbol being generated. We then 
return the normal EOF symbol after next_token() is called once more. To ensure
that EOF is returned normally on this second call, we set the state back to 
YYINITIAL before reporting the error.

String errors such as invalid char (null char), unescaped new line, and 
length exceeding max length are handled inside the string parser function,
by iterating through the characters of the matched token.


